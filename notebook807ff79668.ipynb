{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceType": "competition",
          "sourceId": 132102,
          "databundleVersionId": 15843377
        }
      ],
      "dockerImageVersionId": 31287,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook807ff79668",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "vqHlejiFRaOS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "final_datavidia_10_0_path = kagglehub.competition_download('final-datavidia-10-0')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "MT_87Af3RaOb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:02:17.082806Z",
          "iopub.execute_input": "2026-02-28T06:02:17.083061Z",
          "iopub.status.idle": "2026-02-28T06:02:18.071528Z",
          "shell.execute_reply.started": "2026-02-28T06:02:17.083015Z",
          "shell.execute_reply": "2026-02-28T06:02:18.070798Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "id": "8smqd6DfRaOd",
        "outputId": "b0b5c05c-08a2-4c04-a6cd-abb631c92bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/competitions/final-datavidia-10-0/sample_submission.csv\n/kaggle/input/competitions/final-datavidia-10-0/yelp_academic_dataset_checkin.json\n/kaggle/input/competitions/final-datavidia-10-0/yelp_academic_dataset_business.json\n/kaggle/input/competitions/final-datavidia-10-0/yelp_academic_dataset_tip.json\n/kaggle/input/competitions/final-datavidia-10-0/yelp_academic_dataset_user.json\n/kaggle/input/competitions/final-datavidia-10-0/train.csv\n/kaggle/input/competitions/final-datavidia-10-0/test.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Di Kaggle, aktifkan internet dulu di Settings\n",
        "!pip install transformers datasets torch -q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using: {device}\")\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:05:39.208219Z",
          "iopub.execute_input": "2026-02-28T06:05:39.208563Z",
          "iopub.status.idle": "2026-02-28T06:06:00.54167Z",
          "shell.execute_reply.started": "2026-02-28T06:05:39.208535Z",
          "shell.execute_reply": "2026-02-28T06:06:00.540979Z"
        },
        "id": "OHJvL6o6RaOg",
        "outputId": "d7d0aab5-bf88-4162-9369-0c87ab40dfe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/kaggle/input/competitions/final-datavidia-10-0/'  # sesuaikan path\n",
        "\n",
        "train_df = pd.read_csv(BASE_PATH + 'train.csv')\n",
        "test_df = pd.read_csv(BASE_PATH + 'test.csv')\n",
        "\n",
        "print(f\"Train: {train_df.shape}\")\n",
        "print(f\"Test: {test_df.shape}\")\n",
        "print(train_df['stars'].value_counts().sort_index())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:06:18.570427Z",
          "iopub.execute_input": "2026-02-28T06:06:18.57127Z",
          "iopub.status.idle": "2026-02-28T06:07:37.321356Z",
          "shell.execute_reply.started": "2026-02-28T06:06:18.571241Z",
          "shell.execute_reply": "2026-02-28T06:07:37.320566Z"
        },
        "id": "mnAbcld3RaOi",
        "outputId": "8728ea36-8f9f-4141-d4c2-79ac3cefcadf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train: (5592155, 9)\nTest: (1398125, 8)\nstars\n1.0     855429\n2.0     435751\n3.0     553595\n4.0    1162091\n5.0    2585289\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def add_labels(row):\n",
        "    return f\"{row['text']}\\n\\n(useful = {row['useful']}, funny = {row['funny']}, cool = {row['cool']})\"\n",
        "\n",
        "train_df['text_with_labels'] = train_df.apply(add_labels, axis=1)\n",
        "test_df['text_with_labels'] = test_df.apply(add_labels, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:08:33.330309Z",
          "iopub.execute_input": "2026-02-28T06:08:33.330818Z",
          "iopub.status.idle": "2026-02-28T06:09:39.046985Z",
          "shell.execute_reply.started": "2026-02-28T06:08:33.330792Z",
          "shell.execute_reply": "2026-02-28T06:09:39.046363Z"
        },
        "id": "eVyIwZd9RaOk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== OPSI A: ZERO-SHOT (paling cepat, baseline bagus) =====\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load model yang sudah ditraining pada review 1-5 bintang\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "def predict_stars_zeroshot(texts, batch_size=32):\n",
        "    \"\"\"Predict stars menggunakan nlptown model\"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        # Truncate teks (max 512 token)\n",
        "        batch_truncated = [str(t)[:512] for t in batch]\n",
        "\n",
        "        results = classifier(batch_truncated, truncation=True, max_length=512)\n",
        "\n",
        "        for r in results:\n",
        "            # Label format: \"1 star\", \"2 stars\", dst\n",
        "            star = int(r['label'].split()[0])\n",
        "            predictions.append(star)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"Progress: {i}/{len(texts)}\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Test pada sample kecil dulu\n",
        "sample_texts = test_df['text_with_labels'].fillna('').head(100).tolist()\n",
        "sample_preds = predict_stars_zeroshot(sample_texts)\n",
        "print(\"Sample predictions:\", pd.Series(sample_preds).value_counts())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:12:49.429746Z",
          "iopub.execute_input": "2026-02-28T06:12:49.430435Z",
          "iopub.status.idle": "2026-02-28T06:12:57.523864Z",
          "shell.execute_reply.started": "2026-02-28T06:12:49.430406Z",
          "shell.execute_reply": "2026-02-28T06:12:57.523221Z"
        },
        "id": "E16OXCwFRaOl",
        "outputId": "412b4cfa-211f-4056-83b8-21b423ce0845",
        "colab": {
          "referenced_widgets": [
            "885301f915a346aaa524d7b2b09e9976",
            "3503ef62c6134208941a3cbae9b29846",
            "afafc703eda94efd8fb136794ec55feb",
            "c226678c0fff4b4a8c1bf66a7b069896",
            "ed27a27226d6460f8cb4aa746d6aa3ae",
            "638e8371f93a43608a15245aaa5e2bb0"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "885301f915a346aaa524d7b2b09e9976"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3503ef62c6134208941a3cbae9b29846"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afafc703eda94efd8fb136794ec55feb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c226678c0fff4b4a8c1bf66a7b069896"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed27a27226d6460f8cb4aa746d6aa3ae"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "638e8371f93a43608a15245aaa5e2bb0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Progress: 0/100\nSample predictions: 5    38\n4    24\n1    16\n2    13\n3     9\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== OPSI B: FINE-TUNING (akurasi lebih tinggi) =====\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "MODEL_NAME = \"distilbert-base-uncased\"  # lebih cepat dari BERT\n",
        "# Atau: \"nlptown/bert-base-multilingual-uncased-sentiment\" untuk starting point lebih baik\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class YelpDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, max_len=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])[:1000]  # Limit teks\n",
        "\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "        }\n",
        "\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx] - 1, dtype=torch.long)  # 0-indexed\n",
        "\n",
        "        return item\n",
        "\n",
        "# Sample training (gunakan subset dulu untuk test)\n",
        "SAMPLE_SIZE = 50000  # Mulai dengan 50k, tingkatkan jika waktu cukup\n",
        "\n",
        "train_sample = train_df.sample(n=SAMPLE_SIZE, random_state=42)\n",
        "texts_train = train_sample['text_with_labels'].fillna('').tolist()\n",
        "labels_train = train_sample['stars'].astype(int).tolist()\n",
        "\n",
        "train_dataset = YelpDataset(texts_train, labels_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=5  # 5 kelas (1-5 bintang)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# Training\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(2):  # 2 epoch cukup untuk mulai\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} avg loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Training selesai!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:13:29.087431Z",
          "iopub.execute_input": "2026-02-28T06:13:29.0882Z",
          "iopub.status.idle": "2026-02-28T06:34:54.760372Z",
          "shell.execute_reply.started": "2026-02-28T06:13:29.088169Z",
          "shell.execute_reply": "2026-02-28T06:34:54.759659Z"
        },
        "id": "4z3NLMEBRaOn",
        "outputId": "91d2ef89-d6fa-42e1-fd19-bcbf4c94d055",
        "colab": {
          "referenced_widgets": [
            "2431671b13ec446ba7a9bc3a5e58cd77",
            "4014905954824285a3bdedd077566dcf",
            "39ddb646b9a748349c7deb9d08275f27",
            "6e21a42b2d2c473eb67915de6a0b3c3d",
            "a2587583d25a4e5b8b71885d0d2b9c19",
            "38d28ab0bd384213b8da73a4a73aa3cd"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2431671b13ec446ba7a9bc3a5e58cd77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4014905954824285a3bdedd077566dcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39ddb646b9a748349c7deb9d08275f27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e21a42b2d2c473eb67915de6a0b3c3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2587583d25a4e5b8b71885d0d2b9c19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38d28ab0bd384213b8da73a4a73aa3cd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\nKey                     | Status     | \n------------------------+------------+-\nvocab_transform.weight  | UNEXPECTED | \nvocab_layer_norm.bias   | UNEXPECTED | \nvocab_layer_norm.weight | UNEXPECTED | \nvocab_projector.bias    | UNEXPECTED | \nvocab_transform.bias    | UNEXPECTED | \nclassifier.weight       | MISSING    | \npre_classifier.weight   | MISSING    | \nclassifier.bias         | MISSING    | \npre_classifier.bias     | MISSING    | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1, Batch 0, Loss: 1.5953\nEpoch 1, Batch 100, Loss: 0.9183\nEpoch 1, Batch 200, Loss: 0.8973\nEpoch 1, Batch 300, Loss: 1.0737\nEpoch 1, Batch 400, Loss: 0.7437\nEpoch 1, Batch 500, Loss: 0.5055\nEpoch 1, Batch 600, Loss: 0.6333\nEpoch 1, Batch 700, Loss: 0.8285\nEpoch 1, Batch 800, Loss: 0.5183\nEpoch 1, Batch 900, Loss: 0.5615\nEpoch 1, Batch 1000, Loss: 0.6212\nEpoch 1, Batch 1100, Loss: 0.5348\nEpoch 1, Batch 1200, Loss: 1.0273\nEpoch 1, Batch 1300, Loss: 0.5510\nEpoch 1, Batch 1400, Loss: 0.7245\nEpoch 1, Batch 1500, Loss: 0.7821\nEpoch 1, Batch 1600, Loss: 0.6020\nEpoch 1, Batch 1700, Loss: 0.4786\nEpoch 1, Batch 1800, Loss: 0.7643\nEpoch 1, Batch 1900, Loss: 0.5688\nEpoch 1, Batch 2000, Loss: 0.6385\nEpoch 1, Batch 2100, Loss: 0.6722\nEpoch 1, Batch 2200, Loss: 0.8248\nEpoch 1, Batch 2300, Loss: 0.5598\nEpoch 1, Batch 2400, Loss: 1.0153\nEpoch 1, Batch 2500, Loss: 0.8021\nEpoch 1, Batch 2600, Loss: 0.5680\nEpoch 1, Batch 2700, Loss: 0.6009\nEpoch 1, Batch 2800, Loss: 0.5620\nEpoch 1, Batch 2900, Loss: 0.5557\nEpoch 1, Batch 3000, Loss: 0.3045\nEpoch 1, Batch 3100, Loss: 0.4345\nEpoch 1 avg loss: 0.7524\nEpoch 2, Batch 0, Loss: 0.4495\nEpoch 2, Batch 100, Loss: 0.8280\nEpoch 2, Batch 200, Loss: 0.4795\nEpoch 2, Batch 300, Loss: 1.0456\nEpoch 2, Batch 400, Loss: 0.5121\nEpoch 2, Batch 500, Loss: 0.5514\nEpoch 2, Batch 600, Loss: 0.6334\nEpoch 2, Batch 700, Loss: 0.7191\nEpoch 2, Batch 800, Loss: 0.4375\nEpoch 2, Batch 900, Loss: 0.8271\nEpoch 2, Batch 1000, Loss: 0.3963\nEpoch 2, Batch 1100, Loss: 0.3974\nEpoch 2, Batch 1200, Loss: 0.6497\nEpoch 2, Batch 1300, Loss: 0.5145\nEpoch 2, Batch 1400, Loss: 0.5620\nEpoch 2, Batch 1500, Loss: 0.4402\nEpoch 2, Batch 1600, Loss: 0.5917\nEpoch 2, Batch 1700, Loss: 0.5127\nEpoch 2, Batch 1800, Loss: 0.5149\nEpoch 2, Batch 1900, Loss: 0.6968\nEpoch 2, Batch 2000, Loss: 0.6028\nEpoch 2, Batch 2100, Loss: 0.6348\nEpoch 2, Batch 2200, Loss: 0.3576\nEpoch 2, Batch 2300, Loss: 0.6511\nEpoch 2, Batch 2400, Loss: 0.5250\nEpoch 2, Batch 2500, Loss: 0.7100\nEpoch 2, Batch 2600, Loss: 0.5016\nEpoch 2, Batch 2700, Loss: 0.6739\nEpoch 2, Batch 2800, Loss: 0.5240\nEpoch 2, Batch 2900, Loss: 0.6293\nEpoch 2, Batch 3000, Loss: 0.3745\nEpoch 2, Batch 3100, Loss: 0.6272\nEpoch 2 avg loss: 0.6089\nTraining selesai!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# VALIDASI - cek QWK sebelum submit\n",
        "# ============================================================\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Buat validation set dari train\n",
        "val_size = 5000\n",
        "val_sample = train_df[~train_df.index.isin(train_sample.index)].sample(n=val_size, random_state=42)\n",
        "val_texts = val_sample['text'].fillna('').tolist()\n",
        "val_labels = val_sample['stars'].astype(int).tolist()\n",
        "\n",
        "def evaluate_model(model, texts, labels, batch_size=32):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "\n",
        "    dataset = YelpDataset(texts, labels)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1) + 1  # +1 back to 1-5\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    qwk = cohen_kappa_score(labels, all_preds, weights='quadratic')\n",
        "    print(f\"QWK Score: {qwk:.4f}\")\n",
        "\n",
        "    # Lihat distribusi prediksi\n",
        "    print(\"\\nDistribusi Prediksi:\")\n",
        "    print(pd.Series(all_preds).value_counts().sort_index())\n",
        "    print(\"\\nDistribusi Aktual:\")\n",
        "    print(pd.Series(labels).value_counts().sort_index())\n",
        "\n",
        "    return qwk, all_preds\n",
        "\n",
        "qwk_score, val_preds = evaluate_model(model, val_texts, val_labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:44:41.838671Z",
          "iopub.execute_input": "2026-02-28T06:44:41.839365Z",
          "iopub.status.idle": "2026-02-28T06:45:04.519435Z",
          "shell.execute_reply.started": "2026-02-28T06:44:41.839336Z",
          "shell.execute_reply": "2026-02-28T06:45:04.51867Z"
        },
        "id": "XG6xdj9FRaOq",
        "outputId": "342a00d5-cbaa-4892-d8d2-7b0757cffed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "QWK Score: 0.9002\n\nDistribusi Prediksi:\n1     832\n2     367\n3     329\n4     851\n5    2621\nName: count, dtype: int64\n\nDistribusi Aktual:\n1     737\n2     406\n3     475\n4    1041\n5    2341\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SIMPAN MODEL (penting! jangan sampai hilang)\n",
        "# ============================================================\n",
        "model.save_pretrained('/kaggle/working/distilbert-yelp')\n",
        "tokenizer.save_pretrained('/kaggle/working/distilbert-yelp')\n",
        "print(\"Model tersimpan!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:45:58.184813Z",
          "iopub.execute_input": "2026-02-28T06:45:58.185131Z",
          "iopub.status.idle": "2026-02-28T06:45:58.697334Z",
          "shell.execute_reply.started": "2026-02-28T06:45:58.185105Z",
          "shell.execute_reply": "2026-02-28T06:45:58.696668Z"
        },
        "id": "tg5nGszSRaOs",
        "outputId": "8792f239-b471-421f-cc0c-69a7035ac87e",
        "colab": {
          "referenced_widgets": [
            "4212f50371cb413582d68d141e2cfe66"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4212f50371cb413582d68d141e2cfe66"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Model tersimpan!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PREDIKSI TEST SET & BUAT SUBMISSION\n",
        "# ============================================================\n",
        "def predict_test(model, test_texts, batch_size=32):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "\n",
        "    dataset = YelpDataset(test_texts)  # tanpa labels\n",
        "    loader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1) + 1\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "            if i % 500 == 0:\n",
        "                print(f\"Progress: {i*batch_size}/{len(test_texts)}\")\n",
        "\n",
        "    return all_preds\n",
        "\n",
        "test_texts = test_df['text'].fillna('').tolist()\n",
        "test_preds = predict_test(model, test_texts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-28T06:46:19.683674Z",
          "iopub.execute_input": "2026-02-28T06:46:19.684317Z"
        },
        "id": "VkfFXKfwRaOt",
        "outputId": "b0f073c4-7a85-4b8b-f3f6-b47eaed3cb84"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Progress: 0/1398125\nProgress: 16000/1398125\nProgress: 32000/1398125\nProgress: 48000/1398125\nProgress: 64000/1398125\nProgress: 80000/1398125\nProgress: 96000/1398125\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    'review_id': test_df['review_id'],\n",
        "    'stars': test_preds\n",
        "})\n",
        "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
        "print(\"Submission siap!\")\n",
        "print(submission['stars'].value_counts().sort_index())"
      ],
      "metadata": {
        "trusted": true,
        "id": "o5P4D9hkRaOu"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}